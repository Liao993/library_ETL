version: '3.8'

services:
  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: library_postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./database/init:/docker-entrypoint-initdb.d
    ports:
      - "5433:5432"
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U ${POSTGRES_USER}" ]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - library_network

  # FastAPI Backend
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: library_backend
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - SECRET_KEY=${SECRET_KEY}
      - ALGORITHM=${ALGORITHM}
      - ACCESS_TOKEN_EXPIRE_MINUTES=${ACCESS_TOKEN_EXPIRE_MINUTES}
    volumes:
      - ./backend:/app
    ports:
      - "8000:8000"
    depends_on:
      postgres:
        condition: service_healthy
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
    networks:
      - library_network

  # Streamlit Frontend
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: library_frontend
    environment:
      - API_BASE_URL=${API_BASE_URL}
      - STREAMLIT_SERVER_PORT=${STREAMLIT_SERVER_PORT}
      - STREAMLIT_SERVER_ADDRESS=${STREAMLIT_SERVER_ADDRESS}
    volumes:
      - ./frontend:/app
    ports:
      - "8501:8501"
    depends_on:
      - backend
    networks:
      - library_network

  # ETL Service
  etl:
    build:
      context: ./etl
      dockerfile: Dockerfile
    container_name: library_etl
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - GE_DATA_CONTEXT_ROOT_DIR=${GE_DATA_CONTEXT_ROOT_DIR}
    volumes:
      - ./etl:/app
      - ./data:/data
      - ./credentials:/app/credentials
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - library_network

  # Apache Airflow - PostgreSQL for Airflow metadata
  airflow-postgres:
    image: postgres:15-alpine
    container_name: airflow_postgres
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - airflow_postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U airflow" ]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - library_network

  # Apache Airflow - Webserver
  airflow-webserver:
    build:
      context: ./airflow
      dockerfile: Dockerfile
    container_name: airflow_webserver
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@airflow-postgres/airflow
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW__CORE__FERNET_KEY}
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__WEBSERVER__SECRET_KEY=${AIRFLOW__WEBSERVER__SECRET_KEY}
      - DATABASE_URL=${DATABASE_URL}
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/plugins:/opt/airflow/plugins
      - ./airflow/logs:/opt/airflow/logs
      - ./etl:/opt/airflow/etl
      - ./data:/data
    ports:
      - "8080:8080"
    depends_on:
      airflow-postgres:
        condition: service_healthy
      postgres:
        condition: service_healthy
    command: >
      bash -c "airflow db init &&
               airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com || true &&
               airflow webserver"
    networks:
      - library_network

  # Apache Airflow - Scheduler
  airflow-scheduler:
    build:
      context: ./airflow
      dockerfile: Dockerfile
    container_name: airflow_scheduler
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@airflow-postgres/airflow
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW__CORE__FERNET_KEY}
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - DATABASE_URL=${DATABASE_URL}
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/plugins:/opt/airflow/plugins
      - ./airflow/logs:/opt/airflow/logs
      - ./etl:/opt/airflow/etl
      - ./data:/data
    depends_on:
      airflow-postgres:
        condition: service_healthy
      postgres:
        condition: service_healthy
    command: airflow scheduler
    networks:
      - library_network
  # Airbyte (Optional - can be added later)
  # Uncomment when ready to set up Google Sheets sync
  # airbyte-server:
  #   image: airbyte/server:${AIRBYTE_VERSION}
  #   container_name: airbyte_server
  #   ports:
  #     - "8001:8001"
  #   environment:
  #     - DATABASE_URL=postgresql://airbyte:airbyte@airbyte-postgres:5432/airbyte
  #   depends_on:
  #     - airbyte-postgres
  #   networks:
  #     - library_network

volumes:
  postgres_data:
  airflow_postgres_data:


networks:
  library_network:
    driver: bridge
